{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAI371 – Deep Learning\n",
    "## LAB Exercise – 1\n",
    "Date: 16 – 02 – 2024\n",
    "Duration: 2 Hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from seaborn) (1.26.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/arj/anaconda3/envs/clg/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target for AND function\n",
    "target_and = np.array([[0],[0],[0],[1]])\n",
    "#target for OR function\n",
    "target_or = np.array([[0],[1],[1],[1]])\n",
    "#target for NAND function\n",
    "target_nand = np.array([[1],[1],[1],[0]])\n",
    "#target for XOR function\n",
    "target_xor = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self):\n",
    "\n",
    "    #Train a single layer perceptron.\n",
    "    \n",
    "    # the number of consecutive correct classifications\n",
    "    correct_counter = 0\n",
    "\n",
    "    for train, target in cycle(zip(self.train_data, self.target)):\n",
    "        # end if all points are correctly classified\n",
    "        if correct_counter == len(self.train_data):\n",
    "            break\n",
    "\n",
    "        output = self.classify(train)\n",
    "        self.node_val = train\n",
    "\n",
    "        if output == target:\n",
    "            correct_counter += 1\n",
    "        else:\n",
    "            # if incorrectly classified, update weights and reset correct_counter\n",
    "            self.update_weights(target, output)\n",
    "            correct_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient(self, node, exp, output):\n",
    "    \"\"\"\n",
    "    Return the gradient for a weight.\n",
    "    This is the value of delta-w.\n",
    "    \"\"\"\n",
    "    return node * (exp - output)\n",
    "\n",
    "def update_weights(self, exp, output):\n",
    "    \"\"\"\n",
    "    Update weights and bias based on their respective gradients\n",
    "    \"\"\"\n",
    "    for i in range(self.input_nodes):\n",
    "        self.w[i] += self.lr * self._gradient(self.node_val[i], exp, output)\n",
    "\n",
    "    # the value of the bias node can be considered as being 1 and the weight between this node\n",
    "    # and the output node being self.b\n",
    "    self.b += self.lr * self._gradient(1, exp, output)\n",
    "\n",
    "def forward(self, datapoint):\n",
    "    \"\"\"\n",
    "    One forward pass through the perceptron.\n",
    "    Implementation of \"wX + b\".\n",
    "    \"\"\"\n",
    "    return self.b + np.dot(self.w, datapoint)\n",
    "\n",
    "def classify(self, datapoint):\n",
    "    \"\"\"\n",
    "    Return the class to which a datapoint belongs based on\n",
    "    the perceptron's output for that point.\n",
    "    \"\"\"\n",
    "    if self.forward(datapoint) >= 0:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self, h=0.01):\n",
    "    \"\"\"\n",
    "    Generate plot of input data and decision boundary.\n",
    "    \"\"\"\n",
    "    # setting plot properties like size, theme and axis limits\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize=(20, 20))\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.xlim(-0.1, 1.1)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "\n",
    "    colors = {\n",
    "        0: \"ro\",\n",
    "        1: \"go\"\n",
    "    }\n",
    "\n",
    "    # plotting the four datapoints\n",
    "    for i in range(len(self.train_data)):\n",
    "        plt.plot([self.train_data[i][0]],\n",
    "                 [self.train_data[i][1]],\n",
    "                 colors[self.target[i][0]],\n",
    "                 markersize=20)\n",
    "\n",
    "    x_range = np.arange(-0.1, 1.1, h)\n",
    "    y_range = np.arange(-0.1, 1.1, h)\n",
    "\n",
    "    # creating a mesh to plot decision boundary\n",
    "    xx, yy = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    Z = np.array([[self.classify([x, y]) for x in x_range] for y in y_range])\n",
    "\n",
    "    # using the contourf function to create the plot\n",
    "    plt.contourf(xx, yy, Z, colors=['red', 'green', 'green', 'blue'], alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    Create a perceptron.\n",
    "    train_data: A 4x2 matrix with the input data.\n",
    "    target: A 4x1 matrix with the perceptron's expected outputs\n",
    "    lr: the learning rate. Defaults to 0.01\n",
    "    input_nodes: the number of nodes in the input layer of the perceptron.\n",
    "        Should be equal to the second dimension of train_data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_data, target, lr=0.01, input_nodes=2):\n",
    "        self.train_data = train_data\n",
    "        self.target = target\n",
    "        self.lr = lr\n",
    "        self.input_nodes = input_nodes\n",
    "\n",
    "        # randomly initialize the weights and set the bias to -1.\n",
    "        self.w = np.random.uniform(size=self.input_nodes)\n",
    "        self.b = -1\n",
    "\n",
    "        # node_val hold the values of each node at a given point of time.\n",
    "        self.node_val = np.zeros(self.input_nodes)\n",
    "\n",
    "    def _gradient(self, node, exp, output):\n",
    "        \"\"\"\n",
    "        Return the gradient for a weight.\n",
    "        This is the value of delta-w.\n",
    "        \"\"\"\n",
    "        return node * (exp - output)\n",
    "\n",
    "    def update_weights(self, exp, output):\n",
    "        \"\"\"\n",
    "        Update weights and bias based on their respective gradients\n",
    "        \"\"\"\n",
    "        for i in range(self.input_nodes):\n",
    "            self.w[i] += self.lr * self._gradient(self.node_val[i], exp, output)\n",
    "\n",
    "        # the value of the bias node can be considered as being 1 and the weight between this node\n",
    "        # and the output node being self.b\n",
    "        self.b += self.lr * self._gradient(1, exp, output)\n",
    "\n",
    "    def forward(self, datapoint):\n",
    "        \"\"\"\n",
    "        One forward pass through the perceptron.\n",
    "        Implementation of \"wX + b\".\n",
    "        \"\"\"\n",
    "        return self.b + np.dot(self.w, datapoint)\n",
    "\n",
    "    def classify(self, datapoint):\n",
    "        \"\"\"\n",
    "        Return the class to which a datapoint belongs based on\n",
    "        the perceptron's output for that point.\n",
    "        \"\"\"\n",
    "        if self.forward(datapoint) >= 0:\n",
    "            return 1\n",
    "\n",
    "        return 0\n",
    "    def plot(self, h=0.01):\n",
    "        \"\"\"\n",
    "        Generate plot of input data and decision boundary.\n",
    "        \"\"\"\n",
    "        # setting plot properties like size, theme and axis limits\n",
    "        sns.set_style('darkgrid')\n",
    "        plt.figure(figsize=(20, 20))\n",
    "\n",
    "        plt.axis('scaled')\n",
    "        plt.xlim(-0.1, 1.1)\n",
    "        plt.ylim(-0.1, 1.1)\n",
    "\n",
    "        colors = {\n",
    "            0: \"ro\",\n",
    "            1: \"go\"\n",
    "        }\n",
    "\n",
    "        # plotting the four datapoints\n",
    "        for i in range(len(self.train_data)):\n",
    "            plt.plot([self.train_data[i][0]],\n",
    "                     [self.train_data[i][1]],\n",
    "                     colors[self.target[i][0]],\n",
    "                     markersize=20)\n",
    "\n",
    "        x_range = np.arange(-0.1, 1.1, h)\n",
    "        y_range = np.arange(-0.1, 1.1, h)\n",
    "\n",
    "        # creating a mesh to plot decision boundary\n",
    "        xx, yy = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "        Z = np.array([[self.classify([x, y]) for x in x_range] for y in y_range])\n",
    "\n",
    "        # using the contourf function to create the plot\n",
    "        plt.contourf(xx, yy, Z, colors=['red', 'green', 'green', 'blue'], alpha=0.4)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train a single layer perceptron.\n",
    "        \"\"\"\n",
    "        # the number of consecutive correct classifications\n",
    "        correct_counter = 0\n",
    "\n",
    "        for train, target in cycle(zip(self.train_data, self.target)):\n",
    "            # end if all points are correctly classified\n",
    "            if correct_counter == len(self.train_data):\n",
    "                break\n",
    "\n",
    "            output = self.classify(train)\n",
    "            self.node_val = train\n",
    "\n",
    "            if output == target:\n",
    "                correct_counter += 1\n",
    "            else:\n",
    "                # if incorrectly classified, update weights and reset correct_counter\n",
    "                self.update_weights(target, output)\n",
    "                correct_counter = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3165/2487735181.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.w[i] += self.lr * self._gradient(self.node_val[i], exp, output)\n"
     ]
    }
   ],
   "source": [
    "p_xor = Perceptron(train_data, target_and)\n",
    "p_xor.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference \n",
    "1. [Build your perceptron neural net from scratch](https://medium.com/@ismailghallou/build-your-perceptron-neural-net-from-scratch-e12b7be9d1ef#:~:text=The%20perceptron%20receives%20input%20data,be%20more%20than%202%20inputs%20!)<br>\n",
    "2. [How Neural Networks Solve the XOR Problem](https://towardsdatascience.com/how-neural-networks-solve-the-xor-problem-59763136bdd7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
